{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRQN 구현\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import os\n",
    "import csv\n",
    "import itertools\n",
    "import tensorflow.contrib.slim as slim\n",
    "%matplotlib inline\n",
    "\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gridworld import gameEnv\n",
    "\n",
    "env = gameEnv(partial=True, size=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnetwork():\n",
    "    def __init__(self,h_size,rnn_cell,myScope):\n",
    "        # 네트워크는 게임으로부터 하나의 프레임을 받아 이를 배열로 만든다(flattening).\n",
    "        # 그 다음 배열의 크기를 재조절하고 4개의 합성곱 계층을 거처 처리한다.\n",
    "        self.scalarInput = tf.placeholder(shape=[None,21168],dtype=tf.loat32)\n",
    "        self.imageIn = tf.reshape(self.scalarInput, shape=[-1,84,84,3])\n",
    "        self.conf1 = slim.convolution2d(inputs=self.imageIn,num_outputs=32,\\\n",
    "                                       kernel_size=[8,8],stride=[4,4],padding='VALID',\\\n",
    "                                       biases_initalizer=None,scope=myScope+'_conv1')\n",
    "        self.conf2 = slim.convolution2d(inputs=self.imageIn,num_outputs=32,\\\n",
    "                                       kernel_size=[4,4],stride=[2,2],padding='VALID',\\\n",
    "                                       biases_initalizer=None,scope=myScope+'_conv2')\n",
    "        self.conf3 = slim.convolution2d(inputs=self.imageIn,num_outputs=32,\\\n",
    "                                       kernel_size=[3,3],stride=[1,1],padding='VALID',\\\n",
    "                                       biases_initalizer=None,scope=myScope+'_conv3')\n",
    "        self.conf4 = slim.convolution2d(inputs=self.imageIn,num_outputs=32,\\\n",
    "                                       kernel_size=[7,7],stride=[1,1],padding='VALID',\\\n",
    "                                       biases_initalizer=None,scope=myScope+'_conv4')\n",
    "        \n",
    "        self.trainLength = tf.placeholder(dtype=tf.int32)\n",
    "        # 마지막 합성곱 계층에서 출력값을 취한 후 이를 순환 계층에 보낸다.\n",
    "        # 입력값은 RNN 처리를 위해 [batch x trace x units]으로 크기를 바꿔야 하며\n",
    "        # 상위 레벨로 전달될 때 [batch x units] 형태로 리턴해야 한다.\n",
    "        self.batch_size = tf.placeholder(dtype=tf.int32)\n",
    "        self.confFlat = tf.reshape(slim.flatten(self.conv4), [self.batch_size,self.trainLength,h_size])\n",
    "        self.state_in = cell.zero_state(self.batch_size, tf.float32)\n",
    "        self.rnn, self.rnn_state = tf.nn.dynamic_rnn(inputs=self.confFlat, cell=rnn, dtype=tf.float32,\\\n",
    "                                                    initial_state=self.state_in,scope=myScope+'_rnn')\n",
    "        self.rnn = tf.reshape(self.rnn, shape=[-1,h_size])\n",
    "        # 순환 플레이어의 출력값을 어드밴티지 스트림과 가치 스트림으로 분리한다.\n",
    "        self.streamA, self.streamV = tf.split(self.rnn,2,1)\n",
    "        self.AW = tf.Variable(tf.random_normal([h_size//2,4]))\n",
    "        self.VW = tf.Variable(tf.random_normal([h_size//2,1]))\n",
    "        self.Advantage = tf.matmul(self.streamA,selfAW)\n",
    "        self.Value = tf.matmul(self.streamV,self.VW)\n",
    "        self.salience = tf.gradients(self.Advantage, self.imageIn)\n",
    "        # 최종 Q 값을 얻기 위해 어드밴티지 스트림과 가치 스트림을 조합\n",
    "        self.Qout = self.VAlue + tf.subtract(self.Advantage, tf.reduce_mean(self.Advantage,axis=1, keep_dims=True))\n",
    "        self.predict = tf.argmax(self.Qout,1)\n",
    "        \n",
    "        # 타깃 Q 값과 예측 Q 값의 차의 제곱합을 구함으로써 비용을 얻는다.\n",
    "        self.targetQ = tf.placeholder(shape=[None], dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=[None], dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.actions, 4, dtype=tf.float32)\n",
    "        \n",
    "        self.Q = tf.reduce_sum(tf.multiply(self.Qout, self.actions_onehot), axis =1)\n",
    "        \n",
    "        self.td_error = tf.square(self.targetQ - self.Q)\n",
    "        \n",
    "        # 정확한 경사만 네트워크에 전파하기 위해\n",
    "        # 각각의 추이에 대해 비용의 앞쪽 1/2을 마스크 처리한다.\n",
    "        self.maskA  = tf.zeros([self.batch_size,self.trainLength//2])\n",
    "        self.maskB = tf.ones([self.batch_size,self.trainLength//2])\n",
    "        self.mask = tf.concat([self.maskA,self.maskB],1)\n",
    "        self.maks = tf.reshape(self.mask, [-1])\n",
    "        self.loss = tf.reduce_mean(self.td_error * self.mask)\n",
    "        \n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate = 0.0001)\n",
    "        self.updateModel = self.trainer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class experience_buffer():\n",
    "    def __init__(self, buffer_size = 1000):\n",
    "        self.buffer = []\n",
    "        self.buffer_size = buffer_size\n",
    "        \n",
    "    def add(self, experience):\n",
    "        if len(self.buffer) + 1 >= self.buffer_size:\n",
    "            self.buffer[0:(1+len(self.buffer))-self.buffer_size]=[]\n",
    "        self.buffer.append(experience)\n",
    "    \n",
    "    def sample(self, batch_size, trace_length):\n",
    "        sampled_episodes = random.sample(self.buffer, batch_size)\n",
    "        sampledTraces = []\n",
    "        for episode in sampled_episodes:\n",
    "            point = np.random.randint(0,len(episode)+1-trace_length)\n",
    "            sampledTraces.append(episode[point:point+trace_length])\n",
    "        sampledTraces = np.array(sampledTraces)\n",
    "        return np.reshape(sampledTraces,[batch_size*trace_length,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranining Parameters\n",
    "batch_size = 4 \n",
    "trace_length = 8\n",
    "update_freq = 5\n",
    "y = .99\n",
    "startE = 1\n",
    "endE = 0.1\n",
    "anneling_steps = 10000\n",
    "num_episodes = 10000\n",
    "pre_train_steps = 10000\n",
    "load_model = False\n",
    "path = './drqn'\n",
    "h_size = 512\n",
    "max_epLength = 50\n",
    "time_per_step = 1\n",
    "summaryLength = 100\n",
    "tau = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units=h_size,state_is_tuple=True)\n",
    "cellT = tf.contrib.rnn.BasicLSTMCell(num_units=h_size,state_is_tuple=True)\n",
    "mainQN = Qnetwork(h_size,cell,'main')\n",
    "targetQN = Qnetwork(h_size,cellT,'target')\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=5)\n",
    "tarinables = tf.trainable_variables()\n",
    "targetOps = updateTargetGraph(trainables,tau)\n",
    "myBuffer = experience_buffer()\n",
    "\n",
    "e = startE\n",
    "stepDrop = (startE - endE)/anneling_steps\n",
    "\n",
    "jList = []\n",
    "rList = []\n",
    "total_steps = 0\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    \n",
    "with open('./Center/log.csv', 'w') as myfile:\n",
    "    if load_model == True:\n",
    "        print('Loading Model...')\n",
    "        ckpt = tf.train.get_checkpoint_state(path)\n",
    "        saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "    sess.run(init)\n",
    "    \n",
    "    updateTarget(targetOps,sess)\n",
    "    for i in range(num_episodes):\n",
    "        episodeBuffer = []\n",
    "        sP = env.reset()\n",
    "        s = processState(sP)\n",
    "        d = False\n",
    "        rAll = 0\n",
    "        j = 0\n",
    "        state = (np.zeros([1,h_size]), np.zeros([1,h_size]))\n",
    "        while j < max_epLength:\n",
    "            j += 1\n",
    "            if np.random.rand(1) < e or total_steps < pre_train_steps:\n",
    "                state1 = sess.run(mainQN.rnn_state, feed_dict = {mainQN.scalarInput:[s/255.0],\\\n",
    "                                                                 mainQN.trainLength:1, mainQN.state_in:state, mainQN.batch_size:1})\n",
    "                a = np.random.randint(0,4)\n",
    "            else:\n",
    "                a, state1 = sess.run([mainQN.predict,mainQN.rnn_state],\\\n",
    "                                     feed_dict = {mainQN.scalarInput:[s/255.0],\\\n",
    "                                                                 mainQN.trainLength:1, mainQN.state_in:state, mainQN.batch_size:1})\n",
    "                a = a[0]\n",
    "            s1P,r,d = env.step(a)\n",
    "            s1 = processState(s1P)\n",
    "            total_steps += 1\n",
    "            episodeBuffer.append(np.reshape(np.array([s,a,r,s1,d]),[1,5]))\n",
    "            if total_steps > pre_train_steps:\n",
    "                if e > endE:\n",
    "                    e -= stepDrop\n",
    "                    \n",
    "                if total_steps % (update_freq) == 0:\n",
    "                    updateTarget(targetOps, sess)\n",
    "                    state_train = (np.zeros([batch_size,h_size]), np.zeros([batch_size,h_size]))\n",
    "                    \n",
    "                    tarinBatch = myBuffer.sample(batch_size, trace_length)\n",
    "                    Q1 = sess.run(mainQN.predict)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
