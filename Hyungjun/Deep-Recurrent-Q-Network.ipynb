{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRQN 구현\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'helper'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-dad5d27e2de8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mhelper\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'helper'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import os\n",
    "import csv\n",
    "import itertools\n",
    "import tensorflow.contrib.slim as slim\n",
    "%matplotlib inline\n",
    "\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-2b79bbb50a1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgridworld\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgameEnv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgameEnv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\ReinforcementLearning\\Hyungjun\\gridworld.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "from gridworld import gameEnv\n",
    "\n",
    "env = gameEnv(partial=True, size=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnetwork():\n",
    "    def __init__(self,h_size,rnn_cell,myScope):\n",
    "        # 네트워크는 게임으로부터 하나의 프레임을 받아 이를 배열로 만든다(flattening).\n",
    "        # 그 다음 배열의 크기를 재조절하고 4개의 합성곱 계층을 거처 처리한다.\n",
    "        self.scalarInput = tf.placeholder(shape=[None,21168],dtype=tf.loat32)\n",
    "        self.imageIn = tf.reshape(self.scalarInput, shape=[-1,84,84,3])\n",
    "        self.conf1 = slim.convolution2d(inputs=self.imageIn,num_outputs=32,\\\n",
    "                                       kernel_size=[8,8],stride=[4,4],padding='VALID',\\\n",
    "                                       biases_initalizer=None,scope=myScope+'_conv1')\n",
    "        self.conf2 = slim.convolution2d(inputs=self.imageIn,num_outputs=32,\\\n",
    "                                       kernel_size=[4,4],stride=[2,2],padding='VALID',\\\n",
    "                                       biases_initalizer=None,scope=myScope+'_conv2')\n",
    "        self.conf3 = slim.convolution2d(inputs=self.imageIn,num_outputs=32,\\\n",
    "                                       kernel_size=[3,3],stride=[1,1],padding='VALID',\\\n",
    "                                       biases_initalizer=None,scope=myScope+'_conv3')\n",
    "        self.conf4 = slim.convolution2d(inputs=self.imageIn,num_outputs=32,\\\n",
    "                                       kernel_size=[7,7],stride=[1,1],padding='VALID',\\\n",
    "                                       biases_initalizer=None,scope=myScope+'_conv4')\n",
    "        \n",
    "        self.trainLength = tf.placeholder(dtype=tf.int32)\n",
    "        # 마지막 합성곱 계층에서 출력값을 취한 후 이를 순환 계층에 보낸다.\n",
    "        # 입력값은 RNN 처리를 위해 [batch x trace x units]으로 크기를 바꿔야 하며\n",
    "        # 상위 레벨로 전달될 때 [batch x units] 형태로 리턴해야 한다.\n",
    "        self.batch_size = tf.placeholder(dtype=tf.int32)\n",
    "        self.confFlat = tf.reshape(slim.flatten(self.conv4), [self.batch_size,self.trainLength,h_size])\n",
    "        self.state_in = cell.zero_state(self.batch_size, tf.float32)\n",
    "        self.rnn, self.rnn_state = tf.nn.dynamic_rnn(inputs=self.confFlat, cell=rnn, dtype=tf.float32,\\\n",
    "                                                    initial_state=self.state_in,scope=myScope+'_rnn')\n",
    "        self.rnn = tf.reshape(self.rnn, shape=[-1,h_size])\n",
    "        # 순환 플레이어의 출력값을 어드밴티지 스트림과 가치 스트림으로 분리한다.\n",
    "        self.streamA, self.streamV = tf.split(self.rnn,2,1)\n",
    "        self.AW = tf.Variable(tf.random_normal([h_size//2,4]))\n",
    "        self.VW = tf.Variable(tf.random_normal([h_size//2,1]))\n",
    "        self.Advantage = tf.matmul(self.streamA,selfAW)\n",
    "        self.Value = tf.matmul(self.streamV,self.VW)\n",
    "        self.salience = tf.gradients(self.Advantage, self.imageIn)\n",
    "        # 최종 Q 값을 얻기 위해 어드밴티지 스트림과 가치 스트림을 조합\n",
    "        self.Qout = self.VAlue + tf.subtract(self.Advantage, tf.reduce_mean(self.Advantage,axis=1, keep_dims=True))\n",
    "        self.predict = tf.argmax(self.Qout,1)\n",
    "        \n",
    "        # 타깃 Q 값과 예측 Q 값의 차의 제곱합을 구함으로써 비용을 얻는다.\n",
    "        self.targetQ = tf.placeholder(shape=[None], dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=[None], dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.actions, 4, dtype=tf.float32)\n",
    "        \n",
    "        self.Q = tf.reduce_sum(tf.multiply(self.Qout, self.actions_onehot), axis =1)\n",
    "        \n",
    "        self.td_error = tf.square(self.targetQ - self.Q)\n",
    "        \n",
    "        # 정확한 경사만 네트워크에 전파하기 위해\n",
    "        # 각각의 추이에 대해 비용의 앞쪽 1/2을 마스크 처리한다.\n",
    "        self.maskA  = tf.zeros([self.batch_size,self.trainLength//2])\n",
    "        self.maskB = tf.ones([self.batch_size,self.trainLength//2])\n",
    "        self.mask = tf.concat([self.maskA,self.maskB],1)\n",
    "        self.maks = tf.reshape(self.mask, [-1])\n",
    "        self.loss = tf.reduce_mean(self.td_error * self.mask)\n",
    "        \n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate = 0.0001)\n",
    "        self.updateModel = self.trainer.minimize(self.loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}